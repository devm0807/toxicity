# -*- coding: utf-8 -*-
"""ToxicHead.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dyqVLpVJNtq1mu2OglWgCfSDFpRKyCWB
"""

import gensim
import numpy
import csv
import pandas as pd
from numpy import genfromtxt

from gensim import corpora

!pip install text-preprocessing

import text_preprocessing

from text_preprocessing import *

from pprint import pprint
from collections import defaultdict

from gensim.parsing.preprocessing import remove_stopwords, preprocess_string

df = pd.read_csv('train.csv', sep=',', engine='python', on_bad_lines='warn')

df

text_unprocessed = [i[1] for i in df.values]

[(remove_stopwords(text_unprocessed[1])).split()]

remove_stopwords("Better late than never, but better never late.")

text_removed_stopwords = [(remove_stopwords[i].split(x) for x in " , .") for i in text_unprocessed]

text_removed_stopwords =[]

for i in text_unprocessed:
  x = lemmatize_word(i)
  x = remove_special_character(str(x))
  x = remove_punctuation(x)
  x = remove_number(x)
  x = to_lower(x)

  x = tokenize_word(x)
  x = remove_stopword(x)


  text_removed_stopwords.append(x)

#dont run this  yet

spell = SpellChecker()
for lines in text_removed_stopwords:
  try:
    misspelled = spell.unknown(lines)
  except:
    pass
  for word in range(0,len(lines)):
    if(lines[word] in misspelled):
      lines[word] = spell.correction(lines[word])

text_preprocessed = text_removed_stopwords

frequency = defaultdict(int)
for text in text_preprocessed:
    for token in text:
        frequency[token] += 1

text3 = [
    [token for token in text if frequency[token] > 1]
    for text in text_preprocessed
]

dictionary = corpora.Dictionary(text_preprocessed)
corpus = [dictionary.doc2bow(text) for text in text_preprocessed]

"""That concludes our Preprocessing section

"""

toxic = [i[2] for i in df.values]
toxic.pop(0)
severe_toxic = [i[3] for i in df.values]
severe_toxic.pop(0)
obscene = [i[4] for i in df.values]
obscene.pop(0)
threat =  [i[5] for i in df.values]
threat.pop(0)
insult = [i[6] for i in df.values]
insult.pop(0)
identity_hate = [i[7] for i in df.values]
identity_hate.pop(0)

import numpy as np

labels = np.empty((159571,6,1))

for j in range(1,159572):
  for i in range(0,6):
    labels[j-1][i] = df.values[j][i+2]

"""** NAIVE BAEYESiAN predictor**"""

np.shape([[[1],[2]],[[4],[5]],[[7],[8]]])

a = np.empty((205197,6,1))

P_features=[]

for j in range(0,205197):
  P_features.append(0)
  for k in range(0,159571):
    for t in corpus[k]:
      if t[0]==j:
        P_features[j]+=t[1]
  P_features[j]/=159571

Initialise p_features with length  205197
Then iterate over corpus like so:
for i in range(<corpus length>):
  for t in Corpus[i]:
    p_features[t[0]] += t[1]/159571

p_features=[0 for i in range(0,205197)]
for i in range(0,len(corpus)):
  for t in corpus[i]:
    p_features[t[0]] += t[1]/159571

p_features

for i in range(0,6):
  P_label=0
  for k in range(0,159571):
    if labels[k][i]==1:
      P_label+=1
  P_label = P_label/159571
  for j in range(0,205197):
    P_feat_label=0
    for k in range(0,159571):
      if (labels[k][i]==1):
        for t in corpus[k]:
          if t[0] == j:
            P_feat_label+=t[1]
    P_feat_label=P_feat_label/159571
    a[j][i] = (P_label*P_feat_label)/P_features[j]

num_labels = 6
num_documents = 159571
num_features = 205197

label_count = [0] * num_labels
for k in range(num_documents):
  for i in range(num_labels):
    label_count[i] += labels[k][i]


feature_label_count = [[0] * num_labels for j in range(num_features)]
for k in range(num_documents):
  for t in corpus[k]:
    for i in range(num_labels):
      if labels[k][i]:
        feature_label_count[t[0]][i] += t[1]

for j in range(num_features):
  for i in range(num_labels):
    a[j][i] = ( feature_label_count[j][i]) / (num_documents* p_features[j])

a

pprint(a)

i = "kill gay "
x = lemmatize_word(i)
x = remove_special_character(str(x))
x= remove_punctuation(x)
x = remove_number(x)
x = to_lower(x)
x = tokenize_word(x)
x = remove_stopword(x)

y = dictionary.doc2bow(x)

y

t=[1 for i in range(0,6)]
for i in y:
  for j in range(0,6):
    t[j]*=(1-a[i[0]][j])
for i in range(0,len(t)):
  t[i] = 1 - t[i]

a[i][0]

t



a[i[0]]

a

a[106]